{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:00,375 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import pysam\n",
    "import numpy as np\n",
    "from dragonn.interpret import * \n",
    "from dragonn.vis import *\n",
    "from dragonn.utils import *\n",
    "from keras.models import load_model\n",
    "from concise.metrics import tpr, tnr, fpr, fnr, precision, f1\n",
    "from keras.models import load_model\n",
    "from kerasAC.metrics import recall, specificity, fpr, fnr, precision, f1\n",
    "from kerasAC.custom_losses import ambig_binary_crossentropy, ambig_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:12,231 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:12,241 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:12,272 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:12,273 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:12,274 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:16,858 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:16,923 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:17,187 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:18,042 [WARNING] From /users/annashch/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_prefix=\"/srv/scratch/annashch/bias_correction/\"\n",
    "reg_uncorrected=model_prefix+\"uncorrected/regression/K562/DNASE.K562.regressionlabels.7\"\n",
    "reg_gc_1kb=model_prefix+\"gc_covariate/regression/K562/DNASE.K562.regressionlabels.withgc.7\"\n",
    "reg_gc_200bp=model_prefix+\"gc_covariate_200bp_ave/regression/K562/DNASE.K562.regressionlabels.withgc.7\"\n",
    "reg_gc_110bp_window=model_prefix+\"gc_covariate_110bpwindow/regression/K562/DNASE.K562.regressionlabels.withgc.7\"\n",
    "class_uncorrected=model_prefix+\"uncorrected/classification/K562/DNASE.K562.classificationlabels.7\"\n",
    "class_gc_1kb=model_prefix+\"gc_covariate/classification/K562/DNASE.K562.classificationlabels.withgc.7\"\n",
    "class_gc_200bp=model_prefix+\"gc_covariate_200bp_ave/classification/K562/DNASE.K562.classificationlabels.withgc.7\"\n",
    "class_gc_110bp_window=model_prefix+\"gc_covariate_110bpwindow/classification/K562/DNASE.K562.classificationlabels.withgc.7\"\n",
    "\n",
    "\n",
    "##load the model \n",
    "custom_objects={\"recall\":recall,\n",
    "                \"sensitivity\":recall,\n",
    "                \"specificity\":specificity,\n",
    "                \"fpr\":fpr,\n",
    "                \"fnr\":fnr,\n",
    "                \"precision\":precision,\n",
    "                \"f1\":f1,\n",
    "                \"ambig_binary_crossentropy\":ambig_binary_crossentropy,\n",
    "                \"ambig_mean_squared_error\":ambig_mean_squared_error}\n",
    "model_r_uncorrected=load_model(reg_uncorrected,custom_objects=custom_objects)\n",
    "model_c_uncorrected=load_model(class_uncorrected,custom_objects=custom_objects)\n",
    "\n",
    "model_r_gc_1kb=load_model(reg_gc_1kb,custom_objects=custom_objects)\n",
    "model_c_gc_1kb=load_model(class_gc_1kb,custom_objects=custom_objects)\n",
    "\n",
    "model_r_200bp=load_model(reg_gc_200bp,custom_objects=custom_objects)\n",
    "model_c_200bp=load_model(class_gc_200bp,custom_objects=custom_objects)\n",
    "\n",
    "model_r_110win=load_model(reg_gc_110bp_window,custom_objects=custom_objects)\n",
    "model_c_110win=load_model(class_gc_110bp_window,custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one-hot seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_bed_centered_at_summit(fname,flank):\n",
    "    data=pd.read_csv(fname,header=None,sep='\\t')\n",
    "    data['chrom']=data[0]\n",
    "    data['center']=data[1]+data[9]\n",
    "    data['start']=data['center']-flank\n",
    "    data['end']=data['center']+flank\n",
    "    subset=data[['chrom','start','end']]\n",
    "    inputs=[]\n",
    "    for index,row in subset.iterrows(): \n",
    "        inputs.append((row['chrom'],row['start'],row['end']))\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "def get_seq_from_bed(regions,ref): \n",
    "    ref=pysam.FastaFile(ref)\n",
    "    seqs=[] \n",
    "    for region in regions: \n",
    "        seqs.append(ref.fetch(region[0],region[1],region[2]))        \n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-12 08:57:59,829 [INFO] Note: NumExpr detected 56 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2019-11-12 08:57:59,830 [INFO] NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "flank=500\n",
    "regions=get_bed_centered_at_summit(\"caprin_dnase_intersection.hg38.bed\",flank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_fasta=\"/users/annashch/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta\"\n",
    "seqs=get_seq_from_bed(regions,ref_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dragonn.utils import one_hot_encode\n",
    "seqs_onehot=one_hot_encode(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 1, 1000, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get GC content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiledb\n",
    "#from tiledb \n",
    "gc_array=\"/mnt/data/annotations/gc_content_tracks/tiledb/gc_hg38_110bp_flank.chr11\"\n",
    "gc_array=tiledb.DenseArray(gc_array,'r')[:]['bigwig_track']\n",
    "gc_110bp=[] \n",
    "for entry in regions: \n",
    "    start_pos=entry[1] \n",
    "    end_pos=entry[2] \n",
    "    gc_content=gc_array[start_pos:end_pos][400:600].mean() \n",
    "    gc_110bp.append(gc_content)\n",
    "gc_110bp=np.expand_dims(np.asarray(gc_110bp),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gc_content(seq):\n",
    "    seq=seq.upper() \n",
    "    return (seq.count('G')+seq.count('C'))/len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_1kb=[get_gc_content(seq) for seq in seqs]\n",
    "gc_200bp=[get_gc_content(seq[400:600]) for seq in seqs]\n",
    "\n",
    "gc_1kb=np.expand_dims(np.asarray(gc_1kb),axis=1)\n",
    "gc_200bp=np.expand_dims(np.asarray(gc_200bp),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the gradxinput functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def get_grad_func(cur_model,target_layer_idx): \n",
    "    return K.function(cur_model.inputs,K.gradients(cur_model.layers[target_layer_idx].output,cur_model.inputs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_func_model_r_uncorrected=get_grad_func(model_r_uncorrected,-1)\n",
    "grad_func_model_c_uncorrected=get_grad_func(model_c_uncorrected,-2)\n",
    "grad_func_model_r_gc_1kb=get_grad_func(model_r_gc_1kb,-1)\n",
    "grad_func_model_c_gc_1kb=get_grad_func(model_c_gc_1kb,-2)\n",
    "grad_func_model_r_gc_200bp=get_grad_func(model_r_200bp,-1)\n",
    "grad_func_model_c_gc_200bp=get_grad_func(model_c_200bp,-2)\n",
    "grad_func_model_r_gc_110win=get_grad_func(model_r_110win,-1)\n",
    "grad_func_model_c_gc_110win=get_grad_func(model_c_110win,-2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_r_uncorrected=grad_func_model_r_uncorrected([seqs_onehot])[0]\n",
    "grads_c_uncorrected=grad_func_model_c_uncorrected([seqs_onehot])[0]\n",
    "grads_r_1kb=grad_func_model_r_gc_1kb([seqs_onehot,gc_1kb])[0]\n",
    "grads_c_1kb=grad_func_model_c_gc_1kb([seqs_onehot,gc_1kb])[0]\n",
    "grads_r_200bp=grad_func_model_r_gc_200bp([seqs_onehot,gc_200bp])[0]\n",
    "grads_c_200bp=grad_func_model_c_gc_200bp([seqs_onehot,gc_200bp])[0]\n",
    "grads_r_110win=grad_func_model_r_gc_110win([seqs_onehot,gc_110bp])[0]\n",
    "grads_c_110win=grad_func_model_c_gc_110win([seqs_onehot,gc_110bp])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grads=[grads_r_uncorrected,           \n",
    "           grads_r_1kb,\n",
    "           grads_r_200bp,\n",
    "           grads_r_110win,\n",
    "           grads_c_uncorrected,\n",
    "           grads_c_1kb,\n",
    "           grads_c_200bp,\n",
    "           grads_c_110win]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles=['reg. uncorrected',\n",
    "          'reg. 1kb mean gc',\n",
    "          'reg. 200bp mean gc',\n",
    "          'reg. 110 bp smoothed',\n",
    "          'class. uncorrected',\n",
    "          'class. 1kb mean gc',\n",
    "          'class. 200bp mean gc',\n",
    "          'class. 110 bp smoothed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seq_importance(subtitles, grads, x, xlim=None, ylim=None, figsize=(25, 16),title=\"\",snp_pos=0,axes=None):\n",
    "    \"\"\"Plot  sequence importance score                                                                                                                                                                                                                                 \n",
    "                                                                                                                                                                                                                                                                       \n",
    "    Args:                                                                                                                                                                                                                                                              \n",
    "      grads: either deeplift or gradientxinput score matrix                                                                                                                                                                                                            \n",
    "      x: one-hot encoded DNA sequence                                                                                                                                                                                                                                  \n",
    "      xlim: restrict the plotted xrange                                                                                                                                                                                                                                \n",
    "      figsize: matplotlib figure size                                                                                                                                                                                                                                  \n",
    "    \"\"\"\n",
    "    f,axes=plt.subplots(len(grads),dpi=80,figsize=figsize)\n",
    "    grads=[i.squeeze() for i in grads]\n",
    "    x=x.squeeze()\n",
    "    \n",
    "    seq_len = x.shape[0]\n",
    "    vals_to_plot=[i*x for i in grads]\n",
    "    \n",
    "    if xlim is None:\n",
    "        xlim = (0, seq_len)\n",
    "        \n",
    "   \n",
    "    for i in range(len(grads)):\n",
    "        axes[i]=plot_bases_on_ax(vals_to_plot[i],axes[i],show_ticks=True)\n",
    "        axes[i].set_xlim(xlim)\n",
    "        axes[i].set_title(subtitles[i],fontsize=12)\n",
    "        \n",
    "    plt.xticks(list(range(xlim[0], xlim[1], 5)))\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.savefig(title+'.png',dpi=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(regions)):\n",
    "    region=regions[i]\n",
    "    cur_title='DNAse:'+':'.join([str(j) for j in region])\n",
    "    cur_grads=[a[i] for a in all_grads]\n",
    "    plot_seq_importance(subtitles, \n",
    "                        cur_grads, \n",
    "                        seqs_onehot[i],\n",
    "                        title=cur_title,\n",
    "                        xlim=(400,600))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
