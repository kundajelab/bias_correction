{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T20:53:53.821142Z",
     "start_time": "2020-06-18T20:53:41.958097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/annashch/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/users/annashch/kerasAC/kerasAC/vis/plot_letters.py:173: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  min_coords = np.vstack(data.min(0) for data in polygons_data).min(0)\n",
      "/users/annashch/kerasAC/kerasAC/vis/plot_letters.py:174: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  max_coords = np.vstack(data.max(0) for data in polygons_data).max(0)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import tensorflow\n",
    "from tensorflow.compat.v1.keras.backend import get_session\n",
    "tensorflow.compat.v1.disable_v2_behavior()\n",
    "import kerasAC \n",
    "from kerasAC.generators.tiledb_predict_generator import *\n",
    "from kerasAC.tiledb_config import *\n",
    "import tiledb \n",
    "from scipy.special import softmax\n",
    "from kerasAC.interpret.deepshap import * \n",
    "from kerasAC.interpret.profile_shap import * \n",
    "from kerasAC.vis import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T20:53:56.042524Z",
     "start_time": "2020-06-18T20:53:53.823779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening:/srv/scratch/annashch/bias_correction/enzymatic_bias/tiledb_inputs/merged.SRR1565781.SRR1565782 for reading...\n",
      "success!\n",
      "got indices for used chroms\n",
      "identified task indices:[0]\n",
      "loaded bed regions\n",
      "created generator\n",
      "created predict generator\n"
     ]
    }
   ],
   "source": [
    "gen=TiledbPredictGenerator(ref_fasta=\"/mnt/data/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta\",\n",
    "                    batch_size=1,\n",
    "                    bed_regions_summit_center=True,\n",
    "                    bed_regions=\"/srv/scratch/annashch/bias_correction/enzymatic_bias/profile_model_of_bias/dnase/gm12878.chr1.bed\",\n",
    "                    tdb_array=\"/srv/scratch/annashch/bias_correction/enzymatic_bias/tiledb_inputs/merged.SRR1565781.SRR1565782\",\n",
    "                    chrom_sizes=\"/users/annashch/hg38.chrom.sizes\",\n",
    "                    tdb_input_flank=[673],\n",
    "                    tdb_partition_attribute_for_upsample=[None],\n",
    "                    tdb_input_source_attribute=[\"seq\"],\n",
    "                    tdb_partition_thresh_for_upsample=None,\n",
    "                    tdb_input_aggregation=[None],\n",
    "                    tdb_input_transformation=[None],\n",
    "                    tdb_output_source_attribute=[\"bigwig_track\",\"bigwig_track\"],\n",
    "                    tdb_output_flank=[500,500],\n",
    "                    tdb_output_aggregation=[None,\"sum\"],\n",
    "                    tdb_output_transformation=[None,\"log\"],\n",
    "                    num_inputs=1,\n",
    "                    num_outputs=2,\n",
    "                    upsample_ratio=None,\n",
    "                    tasks=['SRR1565781.SRR1565782'],\n",
    "                    tdb_ambig_attribute=\"ambig_peak\",\n",
    "                    tdb_config=get_default_config(),\n",
    "                    tdb_ctx=tiledb.Ctx(config=get_default_config()),\n",
    "                    num_threads=1)\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T20:53:56.112379Z",
     "start_time": "2020-06-18T20:53:56.044929Z"
    }
   },
   "outputs": [],
   "source": [
    "#load the model! \n",
    "from keras.models import load_model\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from kerasAC.metrics import * \n",
    "from kerasAC.custom_losses import * \n",
    "custom_objects={\"recall\":recall,\n",
    "                    \"sensitivity\":recall,\n",
    "                    \"specificity\":specificity,\n",
    "                    \"fpr\":fpr,\n",
    "                    \"fnr\":fnr,\n",
    "                    \"precision\":precision,\n",
    "                    \"f1\":f1,\n",
    "                    \"ambig_binary_crossentropy\":ambig_binary_crossentropy,\n",
    "                    \"ambig_mean_absolute_error\":ambig_mean_absolute_error,\n",
    "                    \"ambig_mean_squared_error\":ambig_mean_squared_error,\n",
    "                    \"MultichannelMultinomialNLL\":MultichannelMultinomialNLL}\n",
    "get_custom_objects().update(custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T21:31:41.655623Z",
     "start_time": "2020-05-28T21:00:42.143116Z"
    }
   },
   "outputs": [],
   "source": [
    "model=load_model(\"/srv/scratch/annashch/bias_correction/enzymatic_bias/profile_model_of_bias/dnase/bias.dnase.0.hdf5\")\n",
    "model_wrapper=(model.input, model.layers[-1].output)\n",
    "count_explainer=shap.DeepExplainer(model_wrapper,data=create_background,combine_mult_and_diffref=combine_mult_and_diffref_1d)\n",
    "prof_explainer = create_explainer(model)\n",
    "all_coords=[] \n",
    "all_profile_explanations=[] \n",
    "all_count_explanations=[] \n",
    "for i in range(len(gen)): \n",
    "    X,y,coords=gen[i]\n",
    "    coords=coords[0]\n",
    "    profile_explanations=prof_explainer(X[0],None,None)\n",
    "    count_explanations=np.squeeze(count_explainer.shap_values(X)[0])\n",
    "    all_coords.append(coords)\n",
    "    all_profile_explanations.append(profile_explanations)\n",
    "    all_count_explanations.append(count_explanations)\n",
    "    if i%50==0: \n",
    "        print(str(i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T21:31:43.046173Z",
     "start_time": "2020-05-28T21:31:41.658385Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "outputs={} \n",
    "outputs['coords']=all_coords\n",
    "outputs['shap_profile']=all_profile_explanations\n",
    "outputs['shap_counts']=all_count_explanations\n",
    "pickle.dump( outputs,open( \"gm12878.deepshap.bpnet.p\", \"wb\" ) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
